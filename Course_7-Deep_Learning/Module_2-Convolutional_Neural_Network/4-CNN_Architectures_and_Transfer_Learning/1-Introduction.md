# Introduction

Welcome to the session on 'CNN Architectures and Transfer Learning'. 

## In this session

Let’s hear from Ajay about the topics that will be covered in this session.

**VIDEO**

In earlier sessions, you analysed the architecture of VGGNet in detail. In this session, you will study some other famous architectures that had achieved significantly improved performance in the ImageNet competition over their predecessors. Specifically, you will study the architectures of AlexNet, GoogleNet and ResNet. 

You will also learn to use these pre-trained models for different problems using the technique of transfer learning. We will then conclude this session by analysing the performance (not just the accuracy, but efficiency as well) of various popular CNNs for practical deployment purposes using the study published in the paper '_An analysis of Deep Neural Network Models for Practical Applications'_  by A Canziani.  

## People you will hear from in this session

**Faculty:**

**[Samrat Sah](https://in.linkedin.com/in/samrat-sah-7abb0525)**  
Samrat, a graduate of IIT Delhi, is a leading AI practitioner and one of the founding members of a leading AI start-up in India. He has good experience with different Deep Learning technologies such as Computer Vision and Natural Language Processing. He has been mentoring students on these topics as well.

**[Ajay Shenoy](https://in.linkedin.com/in/bastyajayshenoy)**  
Ajay got his PhD in Electrical Engineering from the Indian Institute of Science (IISc) and is a leading researcher in applications of Machine Learning tools for Signal Processing. His other areas of interest include Pattern Recognition, Statistical Learning, Biomedical Signal Processing, Statistical Signal Processing, Compressed Sensing and Optimization.