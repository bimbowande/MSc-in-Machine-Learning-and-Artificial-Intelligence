# Summary

This session was about taking clean text and converting it into a usable text analytics model. In the beginning you learnt feature extraction methods, such as the BoW algorithm and the TFIDF algorithm. You learnt how these algorithms extract features from the text data and you also learnt the differences between them. 

Next, you went through a demonstration of building a sentiment analytics model on the IMDB dataset. The major learnings from the case study were as follows:

1.  Overall process of model building 
    
2.  Comparison between stemming and lemmatisation 
    
3.  Comparison between the models built on features extracted by the BoW and the TFIDF algorithms 
    
4.  Use of pre-trained models, such as TextBlob 
    

Towards the end of the session you learnt the following lexical processing techniques:

1.  Cosine similarity 
    
2.  n-gram model 
    

You also went through a small demonstration of the cosine similarity.

In the lexical processing module, you leant how to build text processing models by learning from the information content in the words, and not from the grammatical structure or the meaning of the words. 

#### Summary

Qn: What are the three most important takeaways for you from this module? 

Ans: *Few important takeaways.*

1. *Feature extraction refers to converting text to numerical data.* 

2. *Once the data is in numerical form; you can build any type of machine learning data on it.* 

3. *You can find similar documents using cosine similarity*

4. *Language models can be used to find the next most probable word.*

In the next module, you will learn syntactic processing. Syntactic model focusses on the grammatical structure of the text. 
