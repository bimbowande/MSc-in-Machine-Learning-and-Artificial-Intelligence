# Summary

In the forthcoming video, we will revisit the topics that this session has covered.

**VIDEO**

So, in this session, you learnt about one-shot detectors. These detectors can predict the output, i.e., the class and location, in a single pass through the network. Let us quickly revise the topics that we discussed in this session:

1.  You started the session with learning about the YOLO detector. You learnt how the model is trained and deployed.  
     
2.  Next, you learnt how to predict the output if more than one bounding box accompanies a single object.  
     
3.  Further, you learnt about the concept of anchor boxes, which come into the picture if there are multiple objects present in the same grid cell.  
     
4.  After completing the theory behind YOLO, you implemented a pretrained YOLO detector to study a real-world use case related to traffic surveillance and solve a problem statement.  
     
5.  Then you learnt about the SSD. You learnt about the concept of multibox and default bounding boxes.  
     
6.  In addition, you learnt about confidence and location loss in the SSD.  
     
7.  Finally, you implemented an SSD pretrained model to detect human faces.

Download the YOLO detector solution notebook below:

Download [Object_detection_YOLO_pretrained_model.ipynb](object_detection_yolov4_pretrained_image.ipynb)

Download the SSD detector solution notebook below:

Download [Face_detection_SSD_pretrained_model.ipynb](face_detector_SSD_caffe.ipynb)

In the next session, you will see the implementation of a **custom** **YOLO** **model** and learn how to write the code for that.